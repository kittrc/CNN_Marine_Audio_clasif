{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "732ea255",
   "metadata": {},
   "source": [
    "# Master"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1d07ac8",
   "metadata": {},
   "source": [
    "#Audio signal processing - FMCC\n",
    "##by Ruwan Abeywardhana. start on Feb-2022\n",
    "\n",
    "#walk through audio file : to search for audio files in data folder # get file names\n",
    "    # calculate FMCC\n",
    "    # save FMCC data into .json file:  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b47ead2",
   "metadata": {},
   "source": [
    "# setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "416bdf40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from scipy.io import wavfile\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from scipy.signal import get_window\n",
    "import scipy.fftpack as fft\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d338b9f0",
   "metadata": {},
   "source": [
    "# # predefined parametere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e4154f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dirData ='./Data'\n",
    "windowTime = 10 # signal length in ms\n",
    "sizeFFT = 2048\n",
    "num_MelPoints = 20 # number of frequancy windows in mel spectrogram\n",
    "dctFilterNum = 40 \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf1f52c3",
   "metadata": {},
   "source": [
    "# function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "962f4921",
   "metadata": {},
   "outputs": [],
   "source": [
    "###### labeling and save data\n",
    "def  encodeLable (dirData):\n",
    "    labelY =[]\n",
    "    for mammalName in os.listdir(dirData): \n",
    "        labelY.append(mammalName)\n",
    "\n",
    "    labelY = pd.array(labelY)\n",
    "    pdY = labelY.reshape((len(labelY), 1))\n",
    "    oe = OrdinalEncoder()\n",
    "    oe.fit(pdY)\n",
    "    encY = oe.transform(pdY)\n",
    "    mapping = { labelY[i]:int(encY[i]) for i in range(len(labelY))}\n",
    "    return mapping\n",
    "\n",
    "##### audio signal pre-processing\n",
    "\n",
    "# extend short signals\n",
    "\n",
    "def AudioNormalize( audio):\n",
    "    audio = audio / np.max(np.abs(audio))\n",
    "    return audio\n",
    "\n",
    "\n",
    "# windowing \n",
    "def AudioWindow (audio, sizeFFT=2048, sizeHop=10, Fs=44100):\n",
    "    \n",
    "    audio = np.pad(audio, int(sizeFFT / 2), mode='reflect')\n",
    "    lenFrame = np.round(Fs * sizeHop / 1000).astype(int)\n",
    "    numFrame = int((len(audio) - sizeFFT) / lenFrame) + 1\n",
    "    audioFrames = np.zeros((numFrame,sizeFFT))\n",
    "    \n",
    "    for n in range(numFrame):\n",
    "        audioFrames[n] = audio[n*lenFrame:n*lenFrame+sizeFFT]\n",
    "    \n",
    "    window = get_window(\"hann\", sizeFFT, fftbins=True)\n",
    "    audioWindow = audioFrames * window\n",
    "\n",
    "    # # for debuggingg\n",
    "    # plt.plot(audioWindow[-1])\n",
    "\n",
    "    return audioWindow\n",
    "    \n",
    "##### frequancy domain analize\n",
    "\n",
    "# FFT calculation \n",
    "def AudioFFT(audioWindow,sizeFFT):\n",
    "    audioFFT = np.empty(( audioWindow.shape[0],int(1 + sizeFFT // 2)), dtype=np.complex64, order='F')\n",
    "    for n in range(audioWindow.shape[0]):\n",
    "        audioFFT[n] = fft.fft(audioWindow[n], axis=0)[:audioFFT.shape[1]]\n",
    "    audioFFT = np.abs(audioFFT)\n",
    "    audioPower = np.square(audioFFT)\n",
    "    return audioPower # audioFFT or audioPower as required\n",
    "\n",
    "# mel frequancy\n",
    "\n",
    "def freq_to_mel(freq):\n",
    "    return 2595.0 * np.log10(1.0 + freq / 700.0)\n",
    "\n",
    "def met_to_freq(mels):\n",
    "    return 700.0 * (10.0**(mels / 2595.0) - 1.0)\n",
    "\n",
    "\n",
    "def GetFilterPoints(frqMin, frqMax, num_MelPoints, sizeFFT, Fs):\n",
    "    melMin = freq_to_mel(frqMin)\n",
    "    melMax = freq_to_mel(frqMax)\n",
    "    \n",
    "    mels = np.linspace(melMin, melMax, num=num_MelPoints+2)\n",
    "    freqs = met_to_freq(mels)\n",
    "    \n",
    "    return np.floor((sizeFFT + 1) / Fs * freqs).astype(int), freqs\n",
    "\n",
    "# normalized filter(weigted maks) for each mel window\n",
    "def GetFilters(melPoints, melFrq,sizeFFT):\n",
    "    melFilters = np.zeros((len(melPoints)-2,int(1+sizeFFT/2)))\n",
    "    \n",
    "    # filter shap triangular\n",
    "    for n in range(len(melPoints)-2):\n",
    "        melFilters[n, melPoints[n] : melPoints[n + 1]] = np.linspace(0, 1, melPoints[n + 1] - melPoints[n]) # incline line or ramp shape\n",
    "        melFilters[n, melPoints[n + 1] : melPoints[n + 2]] = np.linspace(1, 0, melPoints[n + 2] - melPoints[n + 1]) # decline or sawtooth\n",
    "    \n",
    "    enorm = 2.0 / (melFrq[2:len(melFrq)] - melFrq[:len(melFrq)-2])\n",
    "    melFilters *= enorm[:, np.newaxis]\n",
    "    return melFilters\n",
    "\n",
    "# get mel spectrum\n",
    "def MelSpecrum(audioWindow,sizeFFT,Fs):\n",
    "    audioPower = AudioFFT(audioWindow,sizeFFT) # fft or fft-power\n",
    "    melPoints, melFrq = GetFilterPoints(0, Fs/2, num_MelPoints, sizeFFT, Fs) \n",
    "    melFilters = GetFilters(melPoints, melFrq, sizeFFT)\n",
    "    #\n",
    "    audioFiltered = np.dot(melFilters, np.transpose(audioPower))\n",
    "    melSpecrum = 10.0 * np.log10(audioFiltered)\n",
    "    return melSpecrum\n",
    "        \n",
    "\n",
    "# DCT - Cepstral Coefficents\n",
    "\n",
    "def Dct(dctFilterNum, filterLen):\n",
    "    basis = np.empty((dctFilterNum,filterLen))\n",
    "    basis[0, :] = 1.0 / np.sqrt(filterLen)\n",
    "    \n",
    "    samples = np.arange(1, 2 * filterLen, 2) * np.pi / (2.0 * filterLen)\n",
    "\n",
    "    for i in range(1, dctFilterNum):\n",
    "        basis[i, :] = np.cos(i * samples) * np.sqrt(2.0 / filterLen)\n",
    "        \n",
    "    return basis\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "109768a9",
   "metadata": {},
   "source": [
    "# analyze wav file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2339236c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# main walk data directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "efc8838a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_126206/3977146602.py:10: WavFileWarning: Chunk (non-data) not understood, skipping it.\n",
      "  Fs, audio = wavfile.read(audioFileDir) # import audio data\n"
     ]
    }
   ],
   "source": [
    "X = []\n",
    "Y = []\n",
    "mapping = encodeLable (dirData)\n",
    "\n",
    "\n",
    "for mammalName in os.listdir(dirData): # every folder in data directory named after sea mamals \n",
    "\n",
    "    for audioFileName in os.listdir(os.path.join(dirData,mammalName)): # every wav audio files save in the directory\n",
    "        audioFileDir = os.path.join(dirData , mammalName , audioFileName)\n",
    "        Fs, audio = wavfile.read(audioFileDir) # import audio data\n",
    "\n",
    "        ## pre-processing\n",
    "        audio = AudioNormalize(audio)\n",
    "        audioWindow = AudioWindow (audio, sizeFFT=sizeFFT, sizeHop=15, Fs=Fs)\n",
    "\n",
    "        ## frequancy domain analize \n",
    "        # mel spectrogram\n",
    "        melSpecrum = MelSpecrum(audioWindow,sizeFFT,Fs) \n",
    "        # FMCC\n",
    "        dctFilters = Dct(dctFilterNum, num_MelPoints)\n",
    "        mfcc = np.dot(dctFilters, melSpecrum)\n",
    "        #\n",
    "        chunkSize = int(1000//windowTime)\n",
    "        higgLim = chunkSize*mfcc.shape[1]//chunkSize\n",
    "        cutoffHigh = mfcc.shape[1]//chunkSize*chunkSize\n",
    "        fmccReshaped = mfcc[:,0:cutoffHigh].reshape([dctFilterNum,chunkSize,mfcc.shape[1]//chunkSize])\n",
    "        for i in range (fmccReshaped.shape[2]):\n",
    "            X.append(fmccReshaped[:,:,i].tolist())\n",
    "            Y.append(mapping[mammalName])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "badbd0be",
   "metadata": {},
   "source": [
    "# save data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7a8187ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import codecs\n",
    "pathMfcSave ='fmcc_marine_mamal.json'\n",
    "def mfccSaveToJson(pathMfcSave,X,Y,mapping):\n",
    "    json.dump({'X' : np.array(X).tolist(),'Y' : np.array(Y).tolist(),'mapping' :mapping}, \n",
    "              codecs.open(pathMfcSave, 'w', encoding='utf-8'), \n",
    "              separators=(',', ':'), \n",
    "              sort_keys=True, \n",
    "              indent=4) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ad1490bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fmcc data saving completed\n"
     ]
    }
   ],
   "source": [
    "mfccSaveToJson(pathMfcSave,X,Y,mapping)\n",
    "print('fmcc data saving completed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fe9374f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
