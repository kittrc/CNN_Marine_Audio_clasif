{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ce5fdb05",
   "metadata": {},
   "source": [
    "# read Fmcc from .json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7de0263d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import codecs\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e5e39f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ImportMfccData(pathMfccSave):\n",
    "    objDataRead = codecs.open(pathMfccSave, 'r', encoding='utf-8').read()\n",
    "    Rdata = json.loads(objDataRead)\n",
    "    \n",
    "    RX = np.array(Rdata['X'])\n",
    "    RY = np.array(Rdata['Y'])\n",
    "    Rmapping = Rdata['mapping']\n",
    "    return RX,RY,Rmapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b266955d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data importing completed\n"
     ]
    }
   ],
   "source": [
    "pathMfccSave ='fmcc_marine_mamal.json'\n",
    "RX,RY,Rmapping = ImportMfccData(pathMfccSave)\n",
    "print('data importing completed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6a004428",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 2, 3, 4, 5, 6, 7, 8]),\n",
       " array([  16,  213,   57,    3,  264,   71,  201, 1622,   72]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(RY, return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d690d3ed",
   "metadata": {},
   "source": [
    "# prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a0a4f1c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "test_size = 0.25\n",
    "validation_size = 0.2\n",
    "def prepareData (X, Y, test_size, validation_size):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=test_size)\n",
    "    X_train, X_validation, y_train, y_validation = train_test_split(X_train, y_train, test_size=validation_size)\n",
    "        \n",
    "    X_train = X_train[..., np.newaxis] \n",
    "    X_validation = X_validation[..., np.newaxis] \n",
    "    X_test = X_test[..., np.newaxis] \n",
    "\n",
    "    return X_train, X_validation, X_test, y_train, y_validation, y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eda3b378",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train, X_validation, X_test,y_train, y_validation, y_test = prepareData (RX, RY, test_size, validation_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3f194213",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1511, 40, 100, 1)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## debugging\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccc11ece",
   "metadata": {},
   "source": [
    "# Training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "51d02cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f7dbfaa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "end\n"
     ]
    }
   ],
   "source": [
    "def Build_model(input_shape):\n",
    "    \n",
    "    # Instantiate model\n",
    "    model = keras.Sequential()\n",
    "    \n",
    "    # 1st block\n",
    "    model.add(keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape))\n",
    "    model.add(keras.layers.MaxPool2D((3, 3), strides=(2,2), padding='same'))\n",
    "    model.add(keras.layers.BatchNormalization()) # normalizes the activation at the layer, speeds up training\n",
    "              \n",
    "    # 2nd block\n",
    "    model.add(keras.layers.Conv2D(64, (3, 3), activation='relu', input_shape=input_shape))\n",
    "    model.add(keras.layers.MaxPool2D((3, 3), strides=(2,2), padding='same'))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "                  \n",
    "              \n",
    "    # 3rd block\n",
    "    model.add(keras.layers.Conv2D(128, (2, 2), activation='relu', input_shape=input_shape))\n",
    "    model.add(keras.layers.MaxPool2D((2, 2), strides=(2,2), padding='same'))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "              \n",
    "    # flatten\n",
    "    model.add(keras.layers.Flatten()) # flatten  output\n",
    "    model.add(keras.layers.Dense(128, activation='relu'))\n",
    "    model.add(keras.layers.Dropout(0.3)) # randomly drops neurons\n",
    "            \n",
    "    # output layer \n",
    "    model.add(keras.layers.Dense(9, activation='softmax')) \n",
    "    \n",
    "    print(model.summary())\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b8e6233f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 38, 98, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 19, 49, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 19, 49, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 17, 47, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 9, 24, 64)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 9, 24, 64)         256       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 8, 23, 128)        32896     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 4, 12, 128)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 4, 12, 128)        512       \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 6144)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               786560    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 9)                 1161      \n",
      "=================================================================\n",
      "Total params: 840,329\n",
      "Trainable params: 839,881\n",
      "Non-trainable params: 448\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-05 11:30:24.363762: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2022-04-05 11:30:24.364075: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-04-05 11:30:24.365813: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    }
   ],
   "source": [
    "# build the cnn net\n",
    "input_shape = (X_train.shape[1], X_train.shape[2], X_train.shape[3])\n",
    "model = Build_model(input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "91d9d59b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile the network\n",
    "optimizer = keras.optimizers.Adam(learning_rate=0.0001)\n",
    "model.compile(optimizer=optimizer, \n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f1d0c7a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-05 11:30:34.717488: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "2022-04-05 11:30:34.734989: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2494180000 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "63/63 [==============================] - 14s 211ms/step - loss: 0.9206 - accuracy: 0.7319 - val_loss: 0.8706 - val_accuracy: 0.8889\n",
      "Epoch 2/20\n",
      "63/63 [==============================] - 13s 207ms/step - loss: 0.2245 - accuracy: 0.9188 - val_loss: 0.3106 - val_accuracy: 0.9286\n",
      "Epoch 3/20\n",
      "63/63 [==============================] - 12s 191ms/step - loss: 0.1458 - accuracy: 0.9433 - val_loss: 0.1816 - val_accuracy: 0.9365\n",
      "Epoch 4/20\n",
      "63/63 [==============================] - 12s 197ms/step - loss: 0.1100 - accuracy: 0.9519 - val_loss: 0.1527 - val_accuracy: 0.9180\n",
      "Epoch 5/20\n",
      "63/63 [==============================] - 10s 159ms/step - loss: 0.1128 - accuracy: 0.9389 - val_loss: 0.1241 - val_accuracy: 0.9392\n",
      "Epoch 6/20\n",
      "63/63 [==============================] - 9s 144ms/step - loss: 0.1029 - accuracy: 0.9400 - val_loss: 0.1187 - val_accuracy: 0.9180\n",
      "Epoch 7/20\n",
      "63/63 [==============================] - 10s 157ms/step - loss: 0.1034 - accuracy: 0.9411 - val_loss: 0.1144 - val_accuracy: 0.9233\n",
      "Epoch 8/20\n",
      "63/63 [==============================] - 13s 209ms/step - loss: 0.0933 - accuracy: 0.9525 - val_loss: 0.1177 - val_accuracy: 0.9259\n",
      "Epoch 9/20\n",
      "63/63 [==============================] - 12s 185ms/step - loss: 0.1006 - accuracy: 0.9443 - val_loss: 0.1230 - val_accuracy: 0.9233\n",
      "Epoch 10/20\n",
      "63/63 [==============================] - 11s 183ms/step - loss: 0.0881 - accuracy: 0.9463 - val_loss: 0.1126 - val_accuracy: 0.9233\n",
      "Epoch 11/20\n",
      "63/63 [==============================] - 10s 156ms/step - loss: 0.1024 - accuracy: 0.9403 - val_loss: 0.1319 - val_accuracy: 0.9233\n",
      "Epoch 12/20\n",
      "63/63 [==============================] - 9s 149ms/step - loss: 0.0948 - accuracy: 0.9456 - val_loss: 0.1209 - val_accuracy: 0.9074\n",
      "Epoch 13/20\n",
      "63/63 [==============================] - 10s 163ms/step - loss: 0.0830 - accuracy: 0.9600 - val_loss: 0.1172 - val_accuracy: 0.9153\n",
      "Epoch 14/20\n",
      "63/63 [==============================] - 13s 199ms/step - loss: 0.0951 - accuracy: 0.9335 - val_loss: 0.1371 - val_accuracy: 0.9206\n",
      "Epoch 15/20\n",
      "63/63 [==============================] - 12s 198ms/step - loss: 0.0905 - accuracy: 0.9554 - val_loss: 0.1214 - val_accuracy: 0.9153\n",
      "Epoch 16/20\n",
      "63/63 [==============================] - 12s 194ms/step - loss: 0.0973 - accuracy: 0.9314 - val_loss: 0.1210 - val_accuracy: 0.9127\n",
      "Epoch 17/20\n",
      "63/63 [==============================] - 12s 189ms/step - loss: 0.0924 - accuracy: 0.9464 - val_loss: 0.1287 - val_accuracy: 0.9233\n",
      "Epoch 18/20\n",
      "63/63 [==============================] - 12s 190ms/step - loss: 0.0903 - accuracy: 0.9460 - val_loss: 0.1259 - val_accuracy: 0.9127\n",
      "Epoch 19/20\n",
      "63/63 [==============================] - 12s 192ms/step - loss: 0.0832 - accuracy: 0.9470 - val_loss: 0.1148 - val_accuracy: 0.9312\n",
      "Epoch 20/20\n",
      "63/63 [==============================] - 13s 201ms/step - loss: 0.0870 - accuracy: 0.9496 - val_loss: 0.1219 - val_accuracy: 0.9021\n"
     ]
    }
   ],
   "source": [
    "# train the cnn \n",
    "history = model.fit(X_train, y_train, validation_data=(X_validation, y_validation), batch_size=24, epochs=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3a77774c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 1s 70ms/step - loss: 0.1304 - accuracy: 0.9381\n",
      "Accuracy on test set is: 0.938095211982727\n"
     ]
    }
   ],
   "source": [
    "# evaluate \n",
    "\n",
    "test_error, test_accuracy = model.evaluate(X_test, y_test, verbose=1)\n",
    "print(\"Accuracy on test set is: {}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ac3b73a",
   "metadata": {},
   "source": [
    "# Predict Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "cdf3f0b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getKey_fromValue (dictionary, value):\n",
    "    list_Key=  list(dictionary.keys())\n",
    "    list_Value=  list(dictionary.values())\n",
    "    position = list_Value.index(value)\n",
    "    return list_Key[position]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "3fbc543f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Predict(model, X, Rmapping):\n",
    "    X = X[np.newaxis, ...] # 4D np arrya\n",
    "    \n",
    "    prediction = model.predict(X) \n",
    "    \n",
    "    # get the index \n",
    "    predict_index = np.argmax(prediction, axis=1) \n",
    "    \n",
    "    return getKey_fromValue(Rmapping,predict_index[0])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "e4f65057",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Bearded Seal'"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_test=10\n",
    "Predict(model,X_test[index_test],Rmapping)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
